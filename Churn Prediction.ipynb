{
    "cells": [
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Problem: \n\n**Can you develop a machine learning model that predict whether a customer leave the company or not?**\n\n- Many clients of a marketing company use its service to produce advertisiment on their websites.\n\n- Our main objective is to build a machine learning model to help predict which customer will stop their services.\n\n**Dataset Story:**\n\n- Consists of 900 observations and 7 variables. \n- Independent variables contain information about customers.\n- The dependent variable represents the customer abandonment status.\n\n**Variables:**\n\n- Name : Customer's Name\n- Age : Customer's Age\n- Total_Purchase : Customer's total purchase\n- Account_Manager : Is there an account manager(binary)\n- Years : For how many years they have been using it\n- Num_sites : How many websites they use\n- Churn : Customer's churn situation(binary)"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Loading Libraries",
            "execution_count": 22,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import pyspark\nimport pandas as pd\nfrom pyspark.sql import SparkSession, functions as F\nfrom pyspark.sql.functions import col, udf, sum as Fsum, from_unixtime, \\\n    count, countDistinct, when, isnull, max as Fmax, min as Fmin, length, \\\n    month, datediff, first, year, concat\nfrom pyspark.sql.types import IntegerType, FloatType, DateType, TimestampType, LongType, StringType\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import GBTClassifier, RandomForestClassifier, LogisticRegression\nfrom pyspark.ml.evaluation import  MulticlassClassificationEvaluator, BinaryClassificationEvaluator\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nfrom pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier,RandomForestClassifier, LinearSVC, GBTClassifier\nfrom pyspark.ml.feature import StringIndexer, OneHotEncoder, StandardScaler, VectorAssembler, Normalizer, MinMaxScaler, VectorAssembler, HashingTF\nfrom pyspark.mllib.evaluation import MulticlassMetrics\n\n\nfrom pyspark.sql.functions import col,udf, sum as Fsum, from_unixtime,\\\ncount, countDistinct, when, isnull, max as Fmax, min as Fmin, length,\\\nmonth, datediff, first, year, concat\n\nfrom pyspark.sql.types import IntegerType, FloatType, DateType, TimestampType, LongType, StringType",
            "execution_count": 1,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20211117080902-0002\nKERNEL_ID = 92804ef4-4726-4446-8a76-ca2583b60386\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# IBM PAK AUTO CONFIGURATION ON THE GIVEN DATA FOR CREATING SPARK DATA FRAME"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import ibmos2spark, os\n# @hidden_cell\n\nif os.environ.get('RUNTIME_ENV_LOCATION_TYPE') == 'external':\n    endpoint_86d27f644da44c0ba645c5c0d4ed5fbe = 'https://s3.eu.cloud-object-storage.appdomain.cloud'\nelse:\n    endpoint_86d27f644da44c0ba645c5c0d4ed5fbe = 'https://s3.private.eu.cloud-object-storage.appdomain.cloud'\n\ncredentials = {\n    'endpoint': endpoint_86d27f644da44c0ba645c5c0d4ed5fbe,\n    'service_id': 'iam-ServiceId-1f4dc0f7-596c-4019-92e2-f57be3e4fa64',\n    'iam_service_endpoint': 'https://iam.cloud.ibm.com/oidc/token',\n    'api_key': 'rk-btogQrpYD9zXjgre8A3q1tVr-o_SiSPdjsG4OoSPF'\n}\n\nconfiguration_name = 'os_86d27f644da44c0ba645c5c0d4ed5fbe_configs'\ncos = ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name, 'bluemix_cos')\n\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.getOrCreate()\ndf = spark.read\\\n  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n  .option('header', 'true')\\\n  .option(\"header\",True) \\\n  .option(\"inferSchema\",True) \\\n  .option(\"sep\",\",\") \\\n  .option(\"encoding\", \"UTF-8\") \\\n  .load(cos.url('churn.csv', 'churnprediction-donotdelete-pr-40w8lqg9gksy9x'))",
            "execution_count": 3,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df.limit(3).toPandas()",
            "execution_count": 4,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 4,
                    "data": {
                        "text/plain": "              Names   Age  Total_Purchase  Account_Manager  Years  Num_Sites  \\\n0  Cameron Williams  42.0        11066.80                0   7.22        8.0   \n1     Kevin Mueller  41.0        11916.22                0   6.50       11.0   \n2       Eric Lozano  38.0        12884.75                0   6.67       12.0   \n\n   Churn  \n0      1  \n1      1  \n2      1  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Names</th>\n      <th>Age</th>\n      <th>Total_Purchase</th>\n      <th>Account_Manager</th>\n      <th>Years</th>\n      <th>Num_Sites</th>\n      <th>Churn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cameron Williams</td>\n      <td>42.0</td>\n      <td>11066.80</td>\n      <td>0</td>\n      <td>7.22</td>\n      <td>8.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Kevin Mueller</td>\n      <td>41.0</td>\n      <td>11916.22</td>\n      <td>0</td>\n      <td>6.50</td>\n      <td>11.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Eric Lozano</td>\n      <td>38.0</td>\n      <td>12884.75</td>\n      <td>0</td>\n      <td>6.67</td>\n      <td>12.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#Checking Schema of df\ndf.printSchema()",
            "execution_count": 5,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "root\n |-- Names: string (nullable = true)\n |-- Age: double (nullable = true)\n |-- Total_Purchase: double (nullable = true)\n |-- Account_Manager: integer (nullable = true)\n |-- Years: double (nullable = true)\n |-- Num_Sites: double (nullable = true)\n |-- Churn: integer (nullable = true)\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Fixing dtype of 'Num_Sites' from float to integer\ndf = df.withColumn(\"Num_Sites\", df[\"Num_Sites\"].cast(\"integer\"))",
            "execution_count": 6,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Creating a new column to find Purchase in terms of Age\ndf = df.withColumn('purchase_per_site', df.Total_Purchase / df.Num_Sites)",
            "execution_count": 7,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Creating a new column\ndf = df.withColumn('segment', when(df['Years'] < 5, \"Inexpeirenced\").otherwise(\"Expeirenced\"))",
            "execution_count": 8,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# NULL CHECK"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Null check\ndef null_check(df):\n    total_null_count = 0\n    for col_name in df.dtypes:\n        null_count = df.filter((F.col(col_name[0]).isNull()) | (F.col(col_name[0]) == \"\")).count()\n        if (null_count > 0):\n            print(\"{} {} type has {} null values % {}\".format(col_name, col_type[1], null_count,\n                                                              (null_count / df_count * 100)))\n            total_null_count += null_count\n    if total_null_count == 0:\n        print(\"There are no missing values\")",
            "execution_count": 9,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "null_check(df)",
            "execution_count": 10,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "There are no missing values\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df.limit(3).toPandas()",
            "execution_count": 11,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 11,
                    "data": {
                        "text/plain": "              Names   Age  Total_Purchase  Account_Manager  Years  Num_Sites  \\\n0  Cameron Williams  42.0        11066.80                0   7.22          8   \n1     Kevin Mueller  41.0        11916.22                0   6.50         11   \n2       Eric Lozano  38.0        12884.75                0   6.67         12   \n\n   Churn  purchase_per_site      segment  \n0      1        1383.350000  Expeirenced  \n1      1        1083.292727  Expeirenced  \n2      1        1073.729167  Expeirenced  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Names</th>\n      <th>Age</th>\n      <th>Total_Purchase</th>\n      <th>Account_Manager</th>\n      <th>Years</th>\n      <th>Num_Sites</th>\n      <th>Churn</th>\n      <th>purchase_per_site</th>\n      <th>segment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cameron Williams</td>\n      <td>42.0</td>\n      <td>11066.80</td>\n      <td>0</td>\n      <td>7.22</td>\n      <td>8</td>\n      <td>1</td>\n      <td>1383.350000</td>\n      <td>Expeirenced</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Kevin Mueller</td>\n      <td>41.0</td>\n      <td>11916.22</td>\n      <td>0</td>\n      <td>6.50</td>\n      <td>11</td>\n      <td>1</td>\n      <td>1083.292727</td>\n      <td>Expeirenced</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Eric Lozano</td>\n      <td>38.0</td>\n      <td>12884.75</td>\n      <td>0</td>\n      <td>6.67</td>\n      <td>12</td>\n      <td>1</td>\n      <td>1073.729167</td>\n      <td>Expeirenced</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Creating indexer object\nindexer = StringIndexer(inputCol=\"segment\", outputCol=\"segment_label\")",
            "execution_count": 12,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# fitting and transforming the object.\nindexer.fit(df).transform(df).show(3)",
            "execution_count": 13,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "+----------------+----+--------------+---------------+-----+---------+-----+------------------+-----------+-------------+\n|           Names| Age|Total_Purchase|Account_Manager|Years|Num_Sites|Churn| purchase_per_site|    segment|segment_label|\n+----------------+----+--------------+---------------+-----+---------+-----+------------------+-----------+-------------+\n|Cameron Williams|42.0|       11066.8|              0| 7.22|        8|    1|           1383.35|Expeirenced|          0.0|\n|   Kevin Mueller|41.0|      11916.22|              0|  6.5|       11|    1|1083.2927272727272|Expeirenced|          0.0|\n|     Eric Lozano|38.0|      12884.75|              0| 6.67|       12|    1|1073.7291666666667|Expeirenced|          0.0|\n+----------------+----+--------------+---------------+-----+---------+-----+------------------+-----------+-------------+\nonly showing top 3 rows\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# temporarly creating temp_df.\ntemp_sdf = indexer.fit(df).transform(df)",
            "execution_count": 14,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df.printSchema()",
            "execution_count": 15,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "root\n |-- Names: string (nullable = true)\n |-- Age: double (nullable = true)\n |-- Total_Purchase: double (nullable = true)\n |-- Account_Manager: integer (nullable = true)\n |-- Years: double (nullable = true)\n |-- Num_Sites: integer (nullable = true)\n |-- Churn: integer (nullable = true)\n |-- purchase_per_site: double (nullable = true)\n |-- segment: string (nullable = false)\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# It will temporarily do integer over the temp_sdf.\ndf = temp_sdf.withColumn(\"segment_label\", temp_sdf[\"segment_label\"].cast(\"integer\"))",
            "execution_count": 16,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Dropping the column 'segment' \ndf = df.drop('segment')",
            "execution_count": 17,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# stringIndexer"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df.limit(3).toPandas()",
            "execution_count": 18,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 18,
                    "data": {
                        "text/plain": "              Names   Age  Total_Purchase  Account_Manager  Years  Num_Sites  \\\n0  Cameron Williams  42.0        11066.80                0   7.22          8   \n1     Kevin Mueller  41.0        11916.22                0   6.50         11   \n2       Eric Lozano  38.0        12884.75                0   6.67         12   \n\n   Churn  purchase_per_site  segment_label  \n0      1        1383.350000              0  \n1      1        1083.292727              0  \n2      1        1073.729167              0  ",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Names</th>\n      <th>Age</th>\n      <th>Total_Purchase</th>\n      <th>Account_Manager</th>\n      <th>Years</th>\n      <th>Num_Sites</th>\n      <th>Churn</th>\n      <th>purchase_per_site</th>\n      <th>segment_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cameron Williams</td>\n      <td>42.0</td>\n      <td>11066.80</td>\n      <td>0</td>\n      <td>7.22</td>\n      <td>8</td>\n      <td>1</td>\n      <td>1383.350000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Kevin Mueller</td>\n      <td>41.0</td>\n      <td>11916.22</td>\n      <td>0</td>\n      <td>6.50</td>\n      <td>11</td>\n      <td>1</td>\n      <td>1083.292727</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Eric Lozano</td>\n      <td>38.0</td>\n      <td>12884.75</td>\n      <td>0</td>\n      <td>6.67</td>\n      <td>12</td>\n      <td>1</td>\n      <td>1073.729167</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "stringIndexer = StringIndexer(inputCol='Churn', outputCol='label')\ntemp_sdf = stringIndexer.fit(df).transform(df)\ndf = temp_sdf.withColumn(\"label\", temp_sdf[\"label\"].cast(\"integer\"))\n\ndf.show(5)",
            "execution_count": 19,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "+----------------+----+--------------+---------------+-----+---------+-----+------------------+-------------+-----+\n|           Names| Age|Total_Purchase|Account_Manager|Years|Num_Sites|Churn| purchase_per_site|segment_label|label|\n+----------------+----+--------------+---------------+-----+---------+-----+------------------+-------------+-----+\n|Cameron Williams|42.0|       11066.8|              0| 7.22|        8|    1|           1383.35|            0|    1|\n|   Kevin Mueller|41.0|      11916.22|              0|  6.5|       11|    1|1083.2927272727272|            0|    1|\n|     Eric Lozano|38.0|      12884.75|              0| 6.67|       12|    1|1073.7291666666667|            0|    1|\n|   Phillip White|42.0|       8010.76|              0| 6.71|       10|    1|           801.076|            0|    1|\n|  Cynthia Norton|37.0|       9191.58|              0| 5.56|        9|    1|1021.2866666666666|            0|    1|\n+----------------+----+--------------+---------------+-----+---------+-----+------------------+-------------+-----+\nonly showing top 5 rows\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Data Preperation for the Model"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# we specified independent variables to vectorize them as features in next step\ncols = ['Age', 'Total_Purchase', 'Account_Manager', 'Years',\n        'Num_Sites', 'purchase_per_site','segment_label']",
            "execution_count": 20,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# VectorAssembler"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "va = VectorAssembler(inputCols=cols, outputCol=\"features\")\nva_df = va.transform(df)\nva_df.show(3)",
            "execution_count": 21,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "+----------------+----+--------------+---------------+-----+---------+-----+------------------+-------------+-----+--------------------+\n|           Names| Age|Total_Purchase|Account_Manager|Years|Num_Sites|Churn| purchase_per_site|segment_label|label|            features|\n+----------------+----+--------------+---------------+-----+---------+-----+------------------+-------------+-----+--------------------+\n|Cameron Williams|42.0|       11066.8|              0| 7.22|        8|    1|           1383.35|            0|    1|[42.0,11066.8,0.0...|\n|   Kevin Mueller|41.0|      11916.22|              0|  6.5|       11|    1|1083.2927272727272|            0|    1|[41.0,11916.22,0....|\n|     Eric Lozano|38.0|      12884.75|              0| 6.67|       12|    1|1073.7291666666667|            0|    1|[38.0,12884.75,0....|\n+----------------+----+--------------+---------------+-----+---------+-----+------------------+-------------+-----+--------------------+\nonly showing top 3 rows\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Final df\nfinal_df = va_df.select(\"features\", \"label\")\nfinal_df.show(5)",
            "execution_count": 22,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "+--------------------+-----+\n|            features|label|\n+--------------------+-----+\n|[42.0,11066.8,0.0...|    1|\n|[41.0,11916.22,0....|    1|\n|[38.0,12884.75,0....|    1|\n|[42.0,8010.76,0.0...|    1|\n|[37.0,9191.58,0.0...|    1|\n+--------------------+-----+\nonly showing top 5 rows\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Data Splitting"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "train_data, test_data = final_df.randomSplit([0.8, 0.2], seed=12)",
            "execution_count": 23,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# RandomForestClassifier\n\n# create transformers\nscaler = StandardScaler(inputCol='features',outputCol='scaled_features')\nnormalizer = Normalizer(inputCol='scaled_features',outputCol='norm_scaled_features')\n\n# set rf model\nrf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"norm_scaled_features\")\n\n# instantiate pipeline\npipeline = Pipeline(stages=[scaler, normalizer, rf])\n\n# train model\nmodel_rf = pipeline.fit(train_data)\n\n# create prediction column on test data\nresults = model_rf.transform(test_data)\n\n# evaluate results\ncorrect_count = results.filter(results.label == results.prediction).count()\ntotal_count = results.count()\n\ncorrect_1_count = results.filter((results.label == 1) & (results.prediction == 1)).count()\ntotal_1_test = results.filter((results.label == 1)).count()\ntotal_1_predict = results.filter((results.prediction == 1)).count()\n\nprint(\"All correct predections count: \",correct_count)\nprint(\"Total count: \",total_count)\nprint(\"Accuracy %: \",(correct_count / total_count)*100)\nprint(\"Recall %: \",(correct_1_count / total_1_test)*100)\nprint(\"Precision %: \",(correct_1_count / total_1_predict)*100)",
            "execution_count": 24,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "All correct predections count:  153\nTotal count:  184\nAccuracy %:  83.15217391304348\nRecall %:  21.21212121212121\nPrecision %:  58.333333333333336\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python37",
            "display_name": "Python 3.7 with Spark",
            "language": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.7.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}